{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import gzip\n",
    "from rank_gpt import run_retriever, sliding_windows, write_eval_file\n",
    "\n",
    "def load_topics(topics_file):\n",
    "    topics = {}\n",
    "    with open(topics_file, 'r') as f:\n",
    "        for line in f:\n",
    "            qid, query = line.strip().split('\\t')\n",
    "            topics[qid] = query\n",
    "    return topics\n",
    "\n",
    "def get_document_wrapper(doc_id):\n",
    "    try:\n",
    "        document = get_document(doc_id)\n",
    "        return {'docid': doc_id, 'content': document['segment']}\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving document {doc_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_document(doc_id, base_path=\"/root/data/msmarco_v2.1_doc_segmented/\"):\n",
    "    match = re.match(r'msmarco_v2\\.1_doc_(\\d+)_(\\d+)#(\\d+)_(\\d+)', doc_id)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Invalid doc_id format: {doc_id}\")\n",
    "    \n",
    "    shard_number = int(match.group(1))\n",
    "    byte_offset = int(match.group(4))\n",
    "    file_path = os.path.join(base_path, f\"msmarco_v2.1_doc_segmented_{shard_number:02d}.json.gz\")\n",
    "\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        f.seek(byte_offset)\n",
    "        line = f.readline().decode('utf-8')\n",
    "        \n",
    "        try:\n",
    "            document = json.loads(line)\n",
    "            if document['docid'] == doc_id:\n",
    "                return document\n",
    "            else:\n",
    "                raise ValueError(f\"Document at offset does not match requested doc_id: {doc_id}\")\n",
    "        except json.JSONDecodeError:\n",
    "            raise ValueError(f\"Invalid JSON at offset {byte_offset} in file {file_path}\")\n",
    "\n",
    "def load_results(results_file):\n",
    "    results = {}\n",
    "    with open(results_file, 'r') as f:\n",
    "        for line in f:\n",
    "            qid, _, docid, rank, score, _ = line.strip().split()\n",
    "            if qid not in results:\n",
    "                results[qid] = []\n",
    "            results[qid].append({'docid': docid, 'rank': int(rank), 'score': float(score)})\n",
    "    return results\n",
    "\n",
    "# def prepare_rank_results(topics, results):\n",
    "#     rank_results = []\n",
    "#     for qid, query in topics.items():\n",
    "#         if qid in results:\n",
    "#             item = {\"query\": query, \"hits\": []}\n",
    "#             for hit in results[qid]:\n",
    "#                 doc = get_document_wrapper(hit['docid'])\n",
    "#                 if doc:\n",
    "#                     item[\"hits\"].append({\n",
    "#                         \"content\": doc['content'],\n",
    "#                         \"qid\": qid,\n",
    "#                         \"docid\": hit['docid'],\n",
    "#                         \"rank\": hit['rank'],\n",
    "#                         \"score\": hit['score']\n",
    "#                     })\n",
    "#             rank_results.append(item)\n",
    "#     return rank_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from functools import partial\n",
    "def prepare_rank_results(topics, results, max_results=100, max_topics=2, num_processes=16):\n",
    "    rank_results = []\n",
    "    \n",
    "    for qid, query in tqdm(list(topics.items())[:max_topics], desc=\"Processing topics\"):\n",
    "        if qid in results:\n",
    "            hits = results[qid][:max_results]\n",
    "            \n",
    "            with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "                documents = list(tqdm(\n",
    "                    pool.imap(get_document_wrapper, [hit['docid'] for hit in hits]),\n",
    "                    total=len(hits),\n",
    "                    desc=f\"Retrieving documents for query {qid}\"\n",
    "                ))\n",
    "            \n",
    "            item = {\"query\": query, \"hits\": []}\n",
    "            for hit, doc in zip(hits, documents):\n",
    "                if doc:\n",
    "                    item[\"hits\"].append({\n",
    "                        \"content\": doc['content'],\n",
    "                        \"qid\": qid,\n",
    "                        \"docid\": hit['docid'],\n",
    "                        \"rank\": hit['rank'],\n",
    "                        \"score\": hit['score']\n",
    "                    })\n",
    "            \n",
    "            rank_results.append(item)\n",
    "    \n",
    "    return rank_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing topics:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query 2001010: 100%|██████████| 100/100 [00:41<00:00,  2.43it/s]\n",
      "Retrieving documents for query 2001459: 100%|██████████| 100/100 [00:48<00:00,  2.05it/s]\n",
      "Retrieving documents for query 2002075: 100%|██████████| 100/100 [00:46<00:00,  2.13it/s]\n",
      "Processing topics: 100%|██████████| 3/3 [02:16<00:00, 45.60s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]/root/code/python/RankGPT/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranked results have been written to gemini_rerank_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import env\n",
    "topics_file = \"topics.rag24.raggy-dev.txt\"\n",
    "results_file = \"raggy-dev_results.txt\"\n",
    "api_key = env.GOOGLE_API_KEY\n",
    "\n",
    "topics = load_topics(topics_file)\n",
    "results = load_results(results_file)\n",
    "rank_results = prepare_rank_results(topics, results, max_results=100, max_topics=3)\n",
    "\n",
    "new_results = []\n",
    "for item in tqdm(rank_results):\n",
    "    new_item = sliding_windows(\n",
    "        item, \n",
    "        rank_start=0, \n",
    "        rank_end=100, \n",
    "        window_size=100, \n",
    "        # step=10, \n",
    "        model_name='gemini', \n",
    "        api_key=api_key\n",
    "    )\n",
    "    new_results.append(new_item)\n",
    "\n",
    "# Write the reranked results to a file\n",
    "output_file = \"gemini_rerank_test.txt\"\n",
    "write_eval_file(new_results, output_file)\n",
    "\n",
    "print(f\"Reranked results have been written to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
